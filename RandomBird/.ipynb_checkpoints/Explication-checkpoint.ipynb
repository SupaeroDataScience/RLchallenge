{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "EXPLICATION :\n",
    "\n",
    "Pour réussir à obtenir une IA performante, je me suis appuyé sur une default policy assez performante (score variant de 2 à 4).\n",
    "Cette default policy fait que le flappy bird va tout droit quand il est entre les deux prochains tuyaux, monte quand il est en dessous du tuyau le plus bas, et descend quand il est au dessus du tuyau le plus haut.\n",
    "\n",
    "Cependant, cette default policy n'arrive pas à gérer certains changements de hauteurs entre deux couples de tuyaux successifs, ce qui explique les limites de sa performance. Je l'ai donc \"boosté\", par la création de couples états-actions interdits, ou de nouveaux états terminaux.\n",
    "\n",
    "Dans un premier temps, on entraîne notre flappy bird, en utilisant la table count_map. Si un état est stocké dans le tableau count_map, cela signifie qu'il existe une action depuis cet état qui mène à un état terminal. On choisit donc l'autre action.\n",
    "Durant la phase d'entraînement, à chaque fois que le jeu atteint un état terminal, count_map est modifiée. On y rajoute le couple état-action menant à l'état terminal. Si pour un même état, toutes les actions mènent à un état terminal, alors on déclare un nouvel état terminal en propageant l'information vers l'arrière : le couple état-action ayant mené à ce nouvel état terminal est ajouté à count_map. Pour ne pas saturer count_map, on supprime les nouveaux états terminaux de la mémoire, car l'information étant propagé une étape avant, on ne vas retomber dans ces états.\n",
    "\n",
    "Après avoir entraîné notre IA jusqu'à obtenir un tableau count_map contenant environ 20 000 états, notre IA atteint de biens meilleures performances. Sur 100 parties, il obtient des moyennes variant de 7 à 24.\n",
    "\n",
    "La version en python ne contient pas l'entraînement du l'IA, seulement ces performances à partir du tableau de taille 20 000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You're not allowed to change this file\n",
    "from ple.games.flappybird import FlappyBird\n",
    "from ple import PLE\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "step=0\n",
    "lmemory=[None]*6\n",
    "memory=np.array([None]*6)\n",
    "action_seq=[119,119,None]\n",
    "prev_state=0\n",
    "two_steps_previous_action=[None,None]\n",
    "one_step_previous_column=12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_policy(state):\n",
    "    global memory\n",
    "    global action_seq\n",
    "    global prev_state\n",
    "    global step\n",
    "    r=True\n",
    "    rr=False\n",
    "    global two_steps_previous_action\n",
    "    global one_step_previous_column\n",
    "\n",
    "    state_simplif,statelist=statedefine(state)\n",
    "    \n",
    "       \n",
    "  \n",
    "    rr=(one_step_previous_column!=statelist[1])\n",
    "    one_step_previous_column=statelist[1]\n",
    "    single_action=None\n",
    "    if prev_state!=state_simplif:\n",
    "        memory=np.array([None,None,None,None,None,None])\n",
    "        step=0\n",
    "    #define the state\n",
    "    if step%2==0:\n",
    "        # sequence action pour remonter\n",
    "        if state_simplif==-1:\n",
    "            action_seq=[None, 119]\n",
    "    # sequence daction pour descendre    \n",
    "        if state_simplif==1:\n",
    "            action_seq=[None, None]\n",
    "         # define the action:   \n",
    "        single_action=action_seq[0]\n",
    "    if step%2==1:\n",
    "        single_action=action_seq[1]\n",
    "        \n",
    "     # sequence daction pour aller tout droit\n",
    "    if (state_simplif==0) and (memory==np.array([None,119,119,None,None,None])).all():\n",
    "        single_action=None\n",
    "        if r==True:\n",
    "            memory=np.array([119,119,None,None,None,None])\n",
    "            r=False\n",
    "        else :\n",
    "            r=True\n",
    "            memory==np.array([None,None,None,None,None,None])\n",
    "            #single action = 119\n",
    "    \n",
    "    if (prev_state==0 and state_simplif==1 and two_steps_previous_action==[None,119]):\n",
    "        state_simplif=0\n",
    "        memory=np.array([None,None,None,None,None,119])\n",
    "        r=True\n",
    "            \n",
    "    if (state_simplif==0) and (memory==np.array([None,None,119,119,None,None])).all():\n",
    "        memory=memory=np.array([None,119,119,None,None,None])\n",
    "        single_action=None \n",
    "    if (state_simplif==0) and (memory==np.array([None,None,None,119,119,None])).all():\n",
    "        memory=np.array([None,None,119,119,None,None])\n",
    "        single_action=None\n",
    "    if (state_simplif==0) and (memory==np.array([None,None,None,None,119,119])).all():\n",
    "        memory=np.array([None,None,None,119,119,None])\n",
    "        single_action=None\n",
    "    if (state_simplif==0) and (memory==np.array([None,None,None,None,None,119])).all():\n",
    "        memory=np.array([None,None,None,None,119,119])\n",
    "        single_action=119\n",
    "    if (state_simplif==0) and (memory==np.array([None,None,None,None,None,None])).all():\n",
    "        memory=np.array([None,None,None,None,None,119])\n",
    "        single_action=119 \n",
    "        \n",
    "    if (memory==np.array([119,119,None,None,None,None])).all():\n",
    "        memory=np.array([None,None,None,None,None,None])\n",
    "        \n",
    "     \n",
    "    if (two_steps_previous_action==[119,119]):\n",
    "        single_action=None\n",
    "        memory=np.array([None,None,None,119,119,None])\n",
    "    if prev_state-state_simplif==-1 and (two_steps_previous_action[1]==119) :\n",
    "        single_action==119\n",
    "        memory==np.array([None,None,None,None,119,119])\n",
    "        r=True\n",
    "    two_steps_previous_action=[two_steps_previous_action[1]]+[single_action]\n",
    "    \n",
    "    prev_state=state_simplif\n",
    " \n",
    "    if rr:\n",
    "        single_action=state0(step)\n",
    "    #print(single_action)\n",
    "    return single_action\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def state0(memory):\n",
    "    if (memory==np.array([None,None,119,119,None,None])).all():\n",
    "        memory=memory=np.array([None,119,119,None,None,None])\n",
    "        single_action=None \n",
    "    if (memory==np.array([None,None,None,119,119,None])).all():\n",
    "        memory=np.array([None,None,119,119,None,None])\n",
    "        single_action=None\n",
    "    if (memory==np.array([None,None,None,None,119,119])).all():\n",
    "        memory=np.array([None,None,None,119,119,None])\n",
    "        single_action=None\n",
    "    if (memory==np.array([None,None,None,None,None,119])).all():\n",
    "        memory=np.array([None,None,None,None,119,119])\n",
    "        single_action=119\n",
    "    if (memory==np.array([None,None,None,None,None,None])).all():\n",
    "        memory=np.array([None,None,None,None,None,119])\n",
    "        single_action=119 \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def statedefine(state):\n",
    "    statelist=[]\n",
    "    statereduced=[]\n",
    "    for j in state.items():\n",
    "        statelist.append(j[1])\n",
    "    statereduced=[statelist[0]]+statelist[3:5]\n",
    "    state_simplif=0\n",
    "    # axe des y vers le bas\n",
    "    if statereduced[0]>(statereduced[2]-40):\n",
    "        state_simplif=-1# au dessous\n",
    "    if statereduced[0]<(statereduced[1]+40):\n",
    "        state_simplif=1#au dessus\n",
    "     # prochains tuyaux plus hauts-> se mettre le plus en bas possible\n",
    "    if statelist[-1]<statelist[4]:\n",
    "        if statereduced[0]>(statereduced[2]-25):\n",
    "            state_simplif=-1# au dessous\n",
    "        if statereduced[0]<(statereduced[1]+55):\n",
    "            state_simplif=1#au dessus\n",
    "    # prochains tuyaux plus bas-> se mettre le plus en haut possible\n",
    "    if statelist[-1]>statelist[4]:\n",
    "        if statereduced[0]>(statereduced[2]-55):\n",
    "            state_simplif=-1# au dessous\n",
    "        if statereduced[0]<(statereduced[1]+25):\n",
    "            state_simplif=1#au dessus\n",
    "    \n",
    "        \n",
    "    \n",
    "            \n",
    "    return (state_simplif,statereduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def FlappyPolicy(state, screen):\n",
    "    \n",
    "   \n",
    "    global count_map\n",
    "    global step\n",
    "\n",
    "    index_state=0\n",
    "    step+=1\n",
    "    # verifier que letat na pas deja ete rencontre dans count_map:\n",
    "    bool1=(state not in count_map[:,0])\n",
    "    if bool1:\n",
    "        action=default_policy(state)\n",
    "    if not bool1:\n",
    "        index_state=count_map[:,0].tolist().index(state)\n",
    "        \n",
    "        if count_map[index_state,1]==-1:\n",
    "            action=119\n",
    "            \n",
    "        if count_map[index_state,2]==-1:\n",
    "            \n",
    "            action=None\n",
    "            \n",
    "            \n",
    "        if (count_map[index_state,1]==-1) and (count_map[index_state,2]==-1):\n",
    "            print('pas ok')\n",
    "    return action\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# charger le tableau :\n",
    "file_array=\"C:/Users/asus/Desktop/kierszbaum/RLchallenge/RandomBird/Q.npy\"\n",
    "count_map=np.load(file_array)\n",
    "#count_map=np.array([[list([0., 0., 0.]), 0.0, 0.0],[list([0., 0., 0.]), 0.0, 0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def FlappyPolicy(state, screen):\n",
    "    \n",
    "   \n",
    "    global count_map\n",
    "    global step\n",
    "\n",
    "    index_state=0\n",
    "    step+=1\n",
    "    # verifier que letat na pas deja ete rencontre dans count_map:\n",
    "    bool1=(state not in count_map[:,0])\n",
    "    if bool1:\n",
    "        action=default_policy(state)\n",
    "    if not bool1:\n",
    "        index_state=count_map[:,0].tolist().index(state)\n",
    "        \n",
    "        if count_map[index_state,1]==-1:\n",
    "            action=119\n",
    "            \n",
    "        if count_map[index_state,2]==-1:\n",
    "            \n",
    "            action=None\n",
    "            \n",
    "            \n",
    "        if (count_map[index_state,1]==-1) and (count_map[index_state,2]==-1):\n",
    "            print('pas ok')\n",
    "    return action\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ajoute les couples etats actions qui ont mene au crash.\n",
    "# si letat en cours nest pas dans le tableau, on applique normal_policy\n",
    "# si une action a mene au crash pour un meme etat, on change daction cette fois ci.\n",
    "# si les deux actions ont menes au crash pour un meme etat, cet etat devient terminal et on ajoute letat qui a mene a cet \n",
    "# etat terminal dans la memory.\n",
    "\n",
    "def build_memory(count_map, state, action, previous_state, previous_action):\n",
    "    if action is None:\n",
    "        action=1\n",
    "    if action==119:\n",
    "        action=2\n",
    "        \n",
    "    if previous_action is None:\n",
    "        previous_action=1\n",
    "    if previous_action==119:\n",
    "        previous_action=2\n",
    "   \n",
    "    bool1=(state not in count_map[:,0])\n",
    "    if bool1 and (np.shape(count_map)[0]<100000):\n",
    "        a=[state,0.,0.]\n",
    "        a[action]=-1\n",
    "        a=np.reshape(a,newshape=(1,3))\n",
    "        count_map=np.concatenate((count_map,np.array(a)))\n",
    "        #print('apris0')\n",
    "    if not bool1:\n",
    "        index_state=count_map[:,0].tolist().index(state)\n",
    "        count_map[index_state,action]=-1\n",
    "        #print('appris1')\n",
    "        if (count_map[index_state,1]==-1) and (count_map[index_state,2]==-1):\n",
    "            count_map=np.delete(count_map,index_state,0)\n",
    "            # supprime letat terminal de la memoire\n",
    "            a=[previous_state,0.,0.]\n",
    "            a[previous_action]=-1\n",
    "            #print('current state',state)\n",
    "            #print('previous state',previous_state)\n",
    "            a=np.reshape(a,newshape=(1,3))\n",
    "            count_map=np.concatenate((count_map,np.array(a)))\n",
    "            # supprime la possiblite de revenir a letat terminal en rewardant laction qui a mene a letat terminal a -1\n",
    "            #print('appris2')\n",
    "    #print(action)\n",
    "    return count_map\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(file_array, count_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21254\n",
      "21.8\n",
      "197.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-f33a0ff10f05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetGameState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFlappyPolicy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;31m#if reward==1:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-dc171496189b>\u001b[0m in \u001b[0;36mFlappyPolicy\u001b[1;34m(state, screen)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mstep\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# verifier que letat na pas deja ete rencontre dans count_map:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mbool1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcount_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbool1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for k in range(50):\n",
    "    game = FlappyBird(graphics=\"fixed\") # use \"fancy\" for full background, random bird color and random pipe color, use \"fixed\" (default) for black background and constant bird and pipe colors.\n",
    "    p = PLE(game, fps=30, frame_skip=1, num_steps=1, force_fps=True, display_screen=False)\n",
    "# Note: if you want to see you agent act in real time, set force_fps to False. But don't use this setting for learning, just for display purposes.\n",
    "    games=0\n",
    "\n",
    "\n",
    "    for a in range(10):\n",
    "    \n",
    "        p.init()\n",
    "    \n",
    "        previous_state = {'next_next_pipe_bottom_y': 166,'next_next_pipe_dist_to_player': 283.0,'next_next_pipe_top_y': 66,'next_pipe_bottom_y': 135,'next_pipe_dist_to_player': 139.0,'next_pipe_top_y': 35,'player_vel': 1.0,'player_y': 39.0}\n",
    "        previous_action=None\n",
    "    # memory contient les 4 derniers couples etats-actions.\n",
    "    #memory=np.array([[[0.]*8,1]]*4)\n",
    "        memory=np.array([None]*6)\n",
    "        reward = 0.0\n",
    "        screen=0.#juste pour avoir une valeur, on va pas lutiliser\n",
    "        nb_games = 100\n",
    "        cumulated = np.zeros((nb_games))\n",
    "\n",
    "        for i in range(nb_games):\n",
    "            p.reset_game()\n",
    "        \n",
    "            while(not p.game_over()):\n",
    "                state = game.getGameState()\n",
    "            \n",
    "                action=FlappyPolicy(state, screen) \n",
    "                reward = p.act(action)\n",
    "            #if reward==1:\n",
    "             #   print(\"tuyau_passe\")\n",
    "                if p.game_over():\n",
    "                #print(cumulated[i])\n",
    "                    count_map=build_memory(count_map, state, action,previous_state,previous_action)\n",
    "                cumulated[i] = cumulated[i] + reward\n",
    "                previous_state=state\n",
    "                previous_action=action\n",
    "        if a%2==0:\n",
    "            np.save(file_array, count_map)\n",
    "            print(len(count_map[:,0]))\n",
    "            average_score = np.mean(cumulated)\n",
    "            print(average_score)\n",
    "            max_score = np.max(cumulated)\n",
    "            print(max_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20557"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(count_map[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
