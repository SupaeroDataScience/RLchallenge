{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ple.games.flappybird import FlappyBird\n",
    "from ple import PLE\n",
    "\n",
    "import numpy as np\n",
    "#from FlappyAgent import FlappyPolicy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = FlappyBird(graphics=\"fixed\") # use \"fancy\" for full background, random bird color and random pipe color, use \"fixed\" (default) for black background and constant bird and pipe colors.\n",
    "p = PLE(game, fps=30, frame_skip=1, num_steps=1, force_fps=True, display_screen=True)\n",
    "# Note: if you want to see you agent act in real time, set force_fps to False. But don't use this setting for learning, just for display purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Declare functions\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convstate(state):\n",
    "    \"\"\"\n",
    "    Calculate new state variables from game state\n",
    "    \"\"\"\n",
    "    s1 = state['next_pipe_bottom_y'] - state['player_y']\n",
    "    s2 = state['next_pipe_dist_to_player']\n",
    "    s3 = state['player_vel']\n",
    "    \n",
    "    return int(s1-s1%10), int(s2-s2%20), int(s3-s3%2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(key):\n",
    "    if(np.random.rand()<=epsilon): # random action\n",
    "        return np.random.choice([0,1])\n",
    "    \n",
    "    else: \n",
    "        return np.argmax(Q.get(key, [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_trace(key,action):\n",
    "    # Update the trace\n",
    "    global epsTrace\n",
    "    epsTrace = { k: list(map(lambda x: x*gamma*lamb, v)) for k,v in epsTrace.items() }\n",
    "    \n",
    "    if epsTrace.get(key) == None:\n",
    "        epsTrace[key] = [0,0]\n",
    "    \n",
    "    # Remember the current state\n",
    "    epsTrace[key][action] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(delta):\n",
    "    for k,v in epsTrace.items():\n",
    "        Q[k][0] = Q[k][0] + alpha*epsTrace[k][0]*delta\n",
    "        Q[k][1] = Q[k][1] + alpha*epsTrace[k][1]*delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Reinit variables\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metaparameters\n",
    "nb_games = 18000\n",
    "alpha = 0.1 #0.7\n",
    "epsilon = 0.1 #0.4\n",
    "gamma = 0.9\n",
    "lamb = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Run training\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nbgames = 18000\n",
    "\n",
    "# Some control variables\n",
    "cumulated = np.zeros((nb_games))\n",
    "\n",
    "# Start the game\n",
    "p.init()\n",
    "reward = 0\n",
    "\n",
    "for i in range(nb_games):\n",
    "    p.reset_game()\n",
    "    epsTrace = dict()\n",
    "    \n",
    "    # Control print\n",
    "    if i%100 == 0:\n",
    "        print(i, epsilon, alpha, np.mean(cumulated[i-50:i]))\n",
    "        \n",
    "        # Decrease exploration ratio\n",
    "        epsilon = max(epsilon * 0.95, 0.01)\n",
    "        alpha *= 0.995\n",
    "        \n",
    "    if i%1000 == 999:\n",
    "        np.save('Qsarsa_more_%d' % i ,Q)\n",
    "        np.save('cumulated_sarsa_more_%d' % i, cumulated)\n",
    "    \n",
    "    # 0) Retrieve initial state \n",
    "    s1, s2, s3 = convstate(game.getGameState())\n",
    "    current_key = str(s1)+'|'+str(s2)+'|'+str(s3)\n",
    "    \n",
    "    if Q.get(current_key) == None:\n",
    "        Q[current_key] = [0,0]\n",
    "    \n",
    "    # Choose action greedily\n",
    "    a = epsilon_greedy(current_key)\n",
    "    \n",
    "    while(not p.game_over()):\n",
    "        \n",
    "        # Translate action\n",
    "        action = None\n",
    "        if a==1:\n",
    "            action = 119\n",
    "      \n",
    "        # 1) Execute\n",
    "        reward = p.act(action)\n",
    "        cumulated[i] += reward\n",
    "        \n",
    "        ss1, ss2, ss3 = convstate(game.getGameState())\n",
    "        next_key = str(ss1)+'|'+str(ss2)+'|'+str(ss3)\n",
    "\n",
    "        # 2) Choose new action greedily\n",
    "        aa = epsilon_greedy(next_key)\n",
    "        \n",
    "        # 3) Update Q value\n",
    "        # Update trace\n",
    "        update_trace(current_key, a)\n",
    "        \n",
    "        # Update Q\n",
    "        if Q.get(next_key) == None:\n",
    "            Q[next_key] = [0,0]\n",
    "        \n",
    "        delta = reward + gamma*Q[next_key][aa] - Q[current_key][a]\n",
    "        propagate(delta)\n",
    "        \n",
    "        # Update values and map key\n",
    "        s1 = ss1\n",
    "        s2 = ss2\n",
    "        s3 = ss3\n",
    "        a = aa\n",
    "        current_key = next_key   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Postprocess\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean evolution\n",
    "vallist = list()\n",
    "\n",
    "for idx, val in enumerate(cumulated):\n",
    "    if idx < 50:\n",
    "        pass\n",
    "    else: \n",
    "        vallist.append(np.mean( cumulated[idx-50:idx] ))\n",
    "\n",
    "plt.plot(vallist)\n",
    "\n",
    "vallist = list()\n",
    "\n",
    "for idx, val in enumerate(cumulated):\n",
    "    if idx < 500:\n",
    "        pass\n",
    "    else: \n",
    "        vallist.append(np.mean( cumulated[idx-500:idx] ))\n",
    "\n",
    "plt.plot(vallist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
